{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(2)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_metric(ytrue,ypred):\n    score = sum(ypred==ytrue)/len(ypred)\n    return score","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text,remove_stopwords=False):\n    text_new = re.sub('<.*?>','',text) # Removing HTML Tags\n    text_new = re.sub(\"'\\w{1}\",'',text_new) # Removing Apostrophe and 1 letter after that\n    text_new = re.sub('[^a-zA-Z]',' ',text_new) # Removing Everything Except Alphabets\n    text_new = text_new.lower() # Making Everything lower case\n    text_new = ' '.join(text_new.split())# For removing duplicate whitespaces\n    \n    # Removing Stopwords\n    stopwords_list = stopwords.words('english')\n    if remove_stopwords:\n        text_new_list = text_new.split()\n        text_new_list = [i for i in text_new_list if i not in stopwords_list]\n        text_new = ' '.join(text_new_list)\n    \n        # Lemmatization\n    lemmatizer = WordNetLemmatizer()\n    text_new_list = text_new.split()\n    text_new_list = [lemmatizer.lemmatize(word) for word in text_new_list]\n    text_new = ' '.join(text_new_list)\n    \n    return text_new","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review_stop'] = df['review'].apply(lambda x:clean_text(x))\ndf['review_wostop'] = df['review'].apply(lambda x:clean_text(x,remove_stopwords=True))\ndf = df[['review','review_stop','review_wostop','sentiment']]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Encoding the output\nlaben = LabelEncoder()\ndf['sentiment_one_hot'] = laben.fit_transform(df['sentiment'])","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"                                                  review  \\\n0      One of the other reviewers has mentioned that ...   \n1      A wonderful little production. <br /><br />The...   \n2      I thought this was a wonderful way to spend ti...   \n3      Basically there's a family where a little boy ...   \n4      Petter Mattei's \"Love in the Time of Money\" is...   \n...                                                  ...   \n49995  I thought this movie did a down right good job...   \n49996  Bad plot, bad dialogue, bad acting, idiotic di...   \n49997  I am a Catholic taught in parochial elementary...   \n49998  I'm going to have to disagree with the previou...   \n49999  No one expects the Star Trek movies to be high...   \n\n                                             review_stop  \\\n0      one of the other reviewer ha mentioned that af...   \n1      a wonderful little production the filming tech...   \n2      i thought this wa a wonderful way to spend tim...   \n3      basically there a family where a little boy ja...   \n4      petter mattei love in the time of money is a v...   \n...                                                  ...   \n49995  i thought this movie did a down right good job...   \n49996  bad plot bad dialogue bad acting idiotic direc...   \n49997  i am a catholic taught in parochial elementary...   \n49998  i going to have to disagree with the previous ...   \n49999  no one expects the star trek movie to be high ...   \n\n                                           review_wostop sentiment  \\\n0      one reviewer mentioned watching oz episode you...  positive   \n1      wonderful little production filming technique ...  positive   \n2      thought wonderful way spend time hot summer we...  positive   \n3      basically family little boy jake think zombie ...  negative   \n4      petter mattei love time money visually stunnin...  positive   \n...                                                  ...       ...   \n49995  thought movie right good job creative original...  positive   \n49996  bad plot bad dialogue bad acting idiotic direc...  negative   \n49997  catholic taught parochial elementary school nu...  negative   \n49998  going disagree previous comment side maltin on...  negative   \n49999  one expects star trek movie high art fan expec...  negative   \n\n       sentiment_one_hot  \n0                      1  \n1                      1  \n2                      1  \n3                      0  \n4                      1  \n...                  ...  \n49995                  1  \n49996                  0  \n49997                  0  \n49998                  0  \n49999                  0  \n\n[50000 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>review_stop</th>\n      <th>review_wostop</th>\n      <th>sentiment</th>\n      <th>sentiment_one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>one of the other reviewer ha mentioned that af...</td>\n      <td>one reviewer mentioned watching oz episode you...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>a wonderful little production the filming tech...</td>\n      <td>wonderful little production filming technique ...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>i thought this wa a wonderful way to spend tim...</td>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>basically there a family where a little boy ja...</td>\n      <td>basically family little boy jake think zombie ...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>petter mattei love in the time of money is a v...</td>\n      <td>petter mattei love time money visually stunnin...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>i thought this movie did a down right good job...</td>\n      <td>thought movie right good job creative original...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>i am a catholic taught in parochial elementary...</td>\n      <td>catholic taught parochial elementary school nu...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>i going to have to disagree with the previous ...</td>\n      <td>going disagree previous comment side maltin on...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>no one expects the star trek movie to be high ...</td>\n      <td>one expects star trek movie high art fan expec...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Splitting into train and test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = np.random.rand(len(df)) < 0.8\ndf_train = df[mask]\ndf_test = df[~mask]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['sentiment'].value_counts()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"positive    19951\nnegative    19945\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['sentiment'].value_counts()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"negative    5055\npositive    5049\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The train set seems balanced and the same case is with the test set."},{"metadata":{},"cell_type":"markdown","source":"# **Using Tf-Idf Vectorizer without removing stopwords**"},{"metadata":{},"cell_type":"markdown","source":"Here, we apply TfIdf Vectorizer(ngram=1) to sentences. And then it is used to train the Logistic regression model. \nThe matrix is large in dimension. So, we need to delete the training matrices that were being created."},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_list = list(df_train['review_stop'].values)\ntfidf_vectorizer = TfidfVectorizer()\ntrain_sent = tfidf_vectorizer.fit_transform(sentence_list)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sentence_list","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train['sentiment_one_hot'].values\nX_train = train_sent.todense()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(39896, 86525)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(random_state=0)\nlr_res = lr.fit(X_train,y_train)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train,y_train","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_list_test = list(df_test['review_stop'].values)\ny_test = df_test['sentiment_one_hot'].values\ntest_sent = tfidf_vectorizer.transform(sentence_list_test)\nX_test = test_sent.todense()\ny_pred = lr_res.predict(X_test)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred.shape","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(10104,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(10104,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_metric(y_test,y_pred)","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"0.8936064924782264"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_test,y_test","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Using Tf-Idf Vectorizer with removing stopwords**"},{"metadata":{},"cell_type":"markdown","source":"Here, the model is trained on text without stopwords to analyze the effect of stopwords."},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_list = list(df_train['review_wostop'].values)\ntfidf_vectorizer_wo = TfidfVectorizer()\ntrain_sent = tfidf_vectorizer_wo.fit_transform(sentence_list)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sentence_list","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train['sentiment_one_hot'].values\nX_train = train_sent.todense()","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"(39896, 86412)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_wo = LogisticRegression(random_state=0)\nlr_res_wo = lr_wo.fit(X_train,y_train)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train,y_train","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_list_test = list(df_test['review_wostop'].values)\ny_test = df_test['sentiment_one_hot'].values\ntest_sent = tfidf_vectorizer_wo.transform(sentence_list_test)\nX_test = test_sent.todense()","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lr_res_wo.predict(X_test)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred.shape","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"(10104,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_metric(y_test,y_pred)","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"0.896575613618369"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_test,y_test","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Without stopwords,the accuracy is still the same. "},{"metadata":{},"cell_type":"markdown","source":"# Testing models on sample sentence"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentiment_of_sentence(sent,model,vectorizer,le):\n    sent_new = clean_text(sent,remove_stopwords=True)\n    test_sent = vectorizer.transform([sent_new])\n    xtest = test_sent.todense()\n    pred = model.predict(xtest)\n    text = le.inverse_transform(pred)\n    return text[0]","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentiment_of_sentence_with_stopwords(sent,model,vectorizer,le):\n    sent_new = clean_text(sent)\n    test_sent = vectorizer.transform([sent_new])\n    xtest = test_sent.todense()\n    pred = model.predict(xtest)\n    text = le.inverse_transform(pred)\n    return text[0]","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Without Stopwords model\nsample_review = \"This was the best sci-fi movie I have ever seen in a long time. It was a mix of military/war combat with alien sci-fi and the two mixed perfectly.I have very very few complaints about the movie, and despite some of the goofs listed, I don't believe they were substantial enough to change anyone's opinion about the movie. I could have done without some of the corny lines, but they did not deter me at all from the movie. Soon after watching the movie for the first time, I bought it and have already watched it four or five times. The combat and action are really exhilarating and Eckhart is a bad ass actor. Great movie, worth the watch. What I enjoyed most about the movie was the amazing effects with the aliens and the nonstop, in your face combat. There was a constant blaze of gunfire and explosions, the perfect Guy movie but even my girlfriend found the movie to be enjoyable(in moderation of course and she probably likes Eckhart). Once again, an amazing movie, watch it now you will not regret it.\"\nsentiment_of_sentence(sample_review,lr_res_wo,tfidf_vectorizer_wo,laben)","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"'positive'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#With Stopwords model\nsentiment_of_sentence_with_stopwords(sample_review,lr_res,tfidf_vectorizer,laben)","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"'positive'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Using Coefficients of Logistic regression model, we can obtain the polarity scores for different words."},{"metadata":{"trusted":true},"cell_type":"code","source":"#with stopwords coefficient\nfeats = tfidf_vectorizer.get_feature_names()\nvals = lr_res.coef_\nvals = vals.T\nvals = vals.reshape(-1)\n\ndf_dict = {'words':feats,'polarity':vals}\ndf_pol = pd.DataFrame(df_dict)","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pol = df_pol.sort_values(by='polarity').reset_index(drop=True)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#without stopwords coefficient\nfeats_wo = tfidf_vectorizer_wo.get_feature_names()\nvals_wo = lr_res_wo.coef_\nvals_wo = vals_wo.T\nvals_wo = vals_wo.reshape(-1)\n\ndf_dict_wo = {'words':feats_wo,'polarity':vals_wo}\ndf_pol_wo = pd.DataFrame(df_dict_wo)","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pol_wo = df_pol_wo.sort_values(by='polarity').reset_index(drop=True)","execution_count":89,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most Negative 10 words"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pol_wo.head(10)","execution_count":98,"outputs":[{"output_type":"execute_result","execution_count":98,"data":{"text/plain":"      words   polarity\n0     worst -10.790510\n1       bad  -8.218434\n2     waste  -8.115565\n3     awful  -7.942224\n4    boring  -6.806302\n5      poor  -6.485548\n6  terrible  -6.445667\n7   nothing  -5.738112\n8     worse  -5.148191\n9    poorly  -5.134969","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>worst</td>\n      <td>-10.790510</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bad</td>\n      <td>-8.218434</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>waste</td>\n      <td>-8.115565</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>awful</td>\n      <td>-7.942224</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>boring</td>\n      <td>-6.806302</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>poor</td>\n      <td>-6.485548</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>terrible</td>\n      <td>-6.445667</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>nothing</td>\n      <td>-5.738112</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>worse</td>\n      <td>-5.148191</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>poorly</td>\n      <td>-5.134969</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Most positive 10 words"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pol_wo.tail(10)","execution_count":99,"outputs":[{"output_type":"execute_result","execution_count":99,"data":{"text/plain":"           words  polarity\n86402   favorite  4.555936\n86403    enjoyed  4.600914\n86404      loved  4.634686\n86405  brilliant  4.702478\n86406    amazing  5.325924\n86407  wonderful  5.491446\n86408    perfect  5.499082\n86409       best  5.742026\n86410  excellent  7.423399\n86411      great  8.292119","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>86402</th>\n      <td>favorite</td>\n      <td>4.555936</td>\n    </tr>\n    <tr>\n      <th>86403</th>\n      <td>enjoyed</td>\n      <td>4.600914</td>\n    </tr>\n    <tr>\n      <th>86404</th>\n      <td>loved</td>\n      <td>4.634686</td>\n    </tr>\n    <tr>\n      <th>86405</th>\n      <td>brilliant</td>\n      <td>4.702478</td>\n    </tr>\n    <tr>\n      <th>86406</th>\n      <td>amazing</td>\n      <td>5.325924</td>\n    </tr>\n    <tr>\n      <th>86407</th>\n      <td>wonderful</td>\n      <td>5.491446</td>\n    </tr>\n    <tr>\n      <th>86408</th>\n      <td>perfect</td>\n      <td>5.499082</td>\n    </tr>\n    <tr>\n      <th>86409</th>\n      <td>best</td>\n      <td>5.742026</td>\n    </tr>\n    <tr>\n      <th>86410</th>\n      <td>excellent</td>\n      <td>7.423399</td>\n    </tr>\n    <tr>\n      <th>86411</th>\n      <td>great</td>\n      <td>8.292119</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For this model(Tfidf + Logistic Regression), removing stopwords had a minimal impact on the accuracy of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# os.chdir(r'../working')\n# from IPython.display import FileLink\n# FileLink(r'polarity_wo_stopwords.csv')","execution_count":97,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}